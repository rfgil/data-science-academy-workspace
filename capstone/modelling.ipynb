{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1e0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pickle\n",
    "import dill as pickle # https://stackoverflow.com/questions/25348532/can-python-pickle-lambda-functions\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import pyperclip\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#from custom_transformers.utils import variables_mapping\n",
    "from custom_transformers.transformers import PreProcessingTransformer, DropColumnsTransformer, CustomImputer, variables_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc06c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"data\", \"train_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d45d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_patients = pd.read_csv(os.path.join(\"data\", \"duplicated_patients.csv\")).patient_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca0544",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e42b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable into a boolean\n",
    "df['readmitted'] = df['readmitted'] == 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03d20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove patients with corrupted data, without readmissions\n",
    "to_remove = (df.readmitted == False) & (df.patient_id.isin(duplicated_patients))\n",
    "df = df[~to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c11836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54214, 34)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04418d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.readmitted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab65b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance data further by undersampling the non-readmitted\n",
    "remove_n = 54214 - 9072 - 9072\n",
    "\n",
    "np.random.seed(42)\n",
    "drop_indices = np.random.choice(df[df.readmitted == False].index, remove_n, replace=False)\n",
    "df_subset = df.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdbdf3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9072"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.readmitted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2b18ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18144, 34)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297b7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714696b",
   "metadata": {},
   "source": [
    "## train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900ed271",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = ['admission_id', 'patient_id', 'race', 'gender', 'age', 'weight',\n",
    "       'admission_type_code', 'discharge_disposition_code',\n",
    "       'admission_source_code', 'time_in_hospital', 'payer_code',\n",
    "       'medical_specialty', 'has_prosthesis', 'complete_vaccination_status',\n",
    "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
    "       'diag_2', 'diag_3', 'number_diagnoses', 'blood_type',\n",
    "       'hemoglobin_level', 'blood_transfusion', 'max_glu_serum', 'A1Cresult',\n",
    "       'diuretics', 'insulin', 'change', 'diabetesMed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449bd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(df):\n",
    "    X = df[ordered_columns]\n",
    "    y = df['readmitted']\n",
    "    #.apply(lambda value: known_categories['readmitted']['mapping'](value)).astype(known_categories['readmitted']['type'])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f88be85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['readmitted'], random_state=42)\n",
    "\n",
    "X_train, y_train = create_target(df_train)\n",
    "X_test, y_test = create_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6649ab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3629, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dd65151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.readmitted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c30181db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for numeric_column in X_train.select_dtypes(include=[\"int64\"]).columns:\n",
    "#    X_train[numeric_column] = X_train[numeric_column].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4b1e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('dtypes.pickle', 'wb') as fh:\n",
    "#    pickle.dump(X_train.dtypes, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7968352",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f44c5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pieline = make_pipeline(\n",
    "    PreProcessingTransformer(),\n",
    "    DropColumnsTransformer(),\n",
    "    CustomImputer()    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a8258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessingtransformer',\n",
       "                 <custom_transformers.transformers.PreProcessingTransformer object at 0x12d63aed0>),\n",
       "                ('dropcolumnstransformer',\n",
       "                 <custom_transformers.transformers.DropColumnsTransformer object at 0x12d635950>),\n",
       "                ('customimputer',\n",
       "                 <custom_transformers.transformers.CustomImputer object at 0x12d635910>)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pieline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14e347df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admission_id                     int64\n",
       "patient_id                       int64\n",
       "race                            object\n",
       "gender                          object\n",
       "age                             object\n",
       "weight                          object\n",
       "admission_type_code            float64\n",
       "discharge_disposition_code     float64\n",
       "admission_source_code            int64\n",
       "time_in_hospital                 int64\n",
       "payer_code                      object\n",
       "medical_specialty               object\n",
       "has_prosthesis                    bool\n",
       "complete_vaccination_status     object\n",
       "num_lab_procedures             float64\n",
       "num_procedures                   int64\n",
       "num_medications                float64\n",
       "number_outpatient                int64\n",
       "number_emergency                 int64\n",
       "number_inpatient                 int64\n",
       "diag_1                          object\n",
       "diag_2                          object\n",
       "diag_3                          object\n",
       "number_diagnoses                 int64\n",
       "blood_type                      object\n",
       "hemoglobin_level               float64\n",
       "blood_transfusion                 bool\n",
       "max_glu_serum                   object\n",
       "A1Cresult                       object\n",
       "diuretics                       object\n",
       "insulin                         object\n",
       "change                          object\n",
       "diabetesMed                     object\n",
       "readmitted                        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5fb81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression - LogisticRegression\n",
    "#Stochastic gradient descent\n",
    "#Random forest\n",
    "#Gradient boosting classifier\n",
    "categorical_features = [\n",
    "    'admission_type_code',\n",
    "    'discharge_disposition_code',\n",
    "    'admission_source_code',\n",
    "    'payer_code',\n",
    "    'complete_vaccination_status',\n",
    "    'diag_1',\n",
    "    'diag_2',\n",
    "    'diag_3',\n",
    "    'blood_type'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'time_in_hospital',\n",
    "    'has_prosthesis',\n",
    "    'num_lab_procedures',\n",
    "    'num_procedures',\n",
    "    'num_medications',\n",
    "    'number_outpatient',\n",
    "    'number_emergency',\n",
    "    'number_inpatient',\n",
    "    'number_diagnoses',\n",
    "    'hemoglobin_level',\n",
    "    'blood_transfusion',\n",
    "    'A1Cresult',\n",
    "    'diuretics',\n",
    "    'change',\n",
    "    'diabetesMed'\n",
    "]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    PreProcessingTransformer(),\n",
    "    DropColumnsTransformer(),\n",
    "    CustomImputer(),  \n",
    "    #OneHotEncoder(handle_unknown='ignore'),\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)]\n",
    "    ),\n",
    "    #LogisticRegression(random_state=42)\n",
    "    #RandomForestClassifier(random_state=42, max_depth=3, n_estimators=25)\n",
    "    #SGDClassifier(random_state=42, loss = 'log')\n",
    "    GradientBoostingClassifier(random_state=42, n_estimators=15, learning_rate=1.0, max_depth=3)\n",
    "    #LogisticRegression(random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2339bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessingtransformer',\n",
       "                 <custom_transformers.transformers.PreProcessingTransformer object at 0x12d602550>),\n",
       "                ('dropcolumnstransformer',\n",
       "                 <custom_transformers.transformers.DropColumnsTransformer object at 0x12d63a750>),\n",
       "                ('customimputer',\n",
       "                 <custom_transformers.transformers.CustomImputer object at 0x12d63a590>),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransform...\n",
       "                                                   'A1Cresult', 'diuretics',\n",
       "                                                   'change', 'diabetesMed']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['admission_type_code',\n",
       "                                                   'discharge_disposition_code',\n",
       "                                                   'admission_source_code',\n",
       "                                                   'payer_code',\n",
       "                                                   'complete_vaccination_status',\n",
       "                                                   'diag_1', 'diag_2', 'diag_3',\n",
       "                                                   'blood_type'])])),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(learning_rate=1.0, n_estimators=15,\n",
       "                                            random_state=42))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32371f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(pipeline, 'pipeline.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360e3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3080b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eee9740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature number_inpatient (0.683061)\n",
      "2. feature discharge_disposition_code_Discharged to home (0.064717)\n",
      "3. feature discharge_disposition_code_Expired (0.044632)\n",
      "4. feature number_diagnoses (0.020935)\n",
      "5. feature discharge_disposition_code_Discharged/transferred to another rehab fac including rehab units of a hospital (0.019504)\n",
      "6. feature num_medications (0.017035)\n",
      "7. feature number_emergency (0.009563)\n",
      "8. feature num_lab_procedures (0.007730)\n",
      "9. feature num_procedures (0.007660)\n",
      "10. feature discharge_disposition_code_Discharged/transferred to SNF (0.006006)\n",
      "11. feature number_outpatient (0.005698)\n",
      "12. feature diabetesMed (0.005698)\n",
      "13. feature diag_1_diseases of the musculoskeletal system and connective tissue (0.005639)\n",
      "14. feature discharge_disposition_code_Discharged/transferred to home with home health service (0.005511)\n",
      "15. feature discharge_disposition_code_Discharged/transferred to another type of inpatient care institution (0.005430)\n",
      "16. feature payer_code_MC (0.005236)\n",
      "17. feature diag_1_symptoms, signs, and ill-defined conditions (0.004051)\n",
      "18. feature diag_2_neoplasms (0.004020)\n",
      "19. feature admission_source_code_Transfer from a hospital (0.003541)\n",
      "20. feature discharge_disposition_code_Hospice / medical facility (0.003531)\n",
      "21. feature discharge_disposition_code_Hospice / home (0.003491)\n",
      "22. feature A1Cresult (0.003408)\n",
      "23. feature diag_1_injury and poisoning (0.003239)\n",
      "24. feature discharge_disposition_code_Discharged/transferred to another short term hospital (0.003213)\n",
      "25. feature admission_source_code_Emergency Room (0.003048)\n",
      "26. feature admission_source_code_Physician Referral (0.002972)\n",
      "27. feature discharge_disposition_code_Discharged/transferred to a long term care hospital (0.002534)\n",
      "28. feature diag_1_diseases of the skin and subcutaneous tissue (0.002519)\n",
      "29. feature diag_2_endocrine, nutritional and metabolic diseases, and immunity disorders (0.002504)\n",
      "30. feature diag_2_diseases of the skin and subcutaneous tissue (0.002342)\n",
      "31. feature diag_2_mental disorders (0.002333)\n",
      "32. feature discharge_disposition_code_Discharged/transferred within this institution to Medicare approved swing bed (0.002135)\n",
      "33. feature diag_2_diseases of the genitourinary system (0.002084)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h7/rp8ld5_n2ld57w78vzqvcrx40000gp/T/ipykernel_3552/3474095340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d. feature %s (%f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_forest_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/h7/rp8ld5_n2ld57w78vzqvcrx40000gp/T/ipykernel_3552/3474095340.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d. feature %s (%f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_forest_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "categorical_encode_step = pipeline.named_steps['columntransformer'].named_transformers_['cat']\n",
    "random_forest_step = pipeline.named_steps['gradientboostingclassifier']\n",
    "#random_forest_step = pipeline.named_steps['randomforestclassifier']\n",
    "\n",
    "onehot_columns = categorical_encode_step.get_feature_names(input_features=categorical_features)\n",
    "\n",
    "importances = pd.Series(data=random_forest_step.feature_importances_, index = np.array(numerical_features + list(onehot_columns)))\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, importances.index[indices[f]], importances[indices[f]]))\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in random_forest_step.estimators_], axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "\n",
    "MAX_FEAT = 15\n",
    "plt.bar(x=importances.index[indices][:MAX_FEAT], height=importances[indices][:MAX_FEAT],\n",
    "        color=\"r\", yerr=std[indices][:MAX_FEAT], align=\"center\");\n",
    "plt.xticks(range(len(importances.index[indices][:MAX_FEAT])), importances.index[indices][:MAX_FEAT], rotation=45, ha=\"right\")\n",
    "#plt.xlim([-1, X_train.shape[1]])\n",
    "#plt.xlabel('Features');\n",
    "plt.ylabel('Importance');\n",
    "\n",
    "plt.gcf().set_size_inches(12,4)\n",
    "plt.gcf().savefig(\"images/feature_importance.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe95e1",
   "metadata": {},
   "source": [
    "## Analysing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2f4d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(preds_proba, y_test, min_recall=0.5, min_precision=0.65):\n",
    "\n",
    "    threshold = 0.5\n",
    "    threshold_recall = 0\n",
    "    threshold_precision = 0\n",
    "\n",
    "    best_f1score = 0\n",
    "\n",
    "    for i in range(100):\n",
    "        current_threshold = i / 100\n",
    "\n",
    "        best_preds = preds_proba > current_threshold\n",
    "        \n",
    "        precision = precision_score(y_test, best_preds) #, pos_label=True)\n",
    "        recall = recall_score(y_test, best_preds)\n",
    "        \n",
    "        f1score = f1_score(y_test, best_preds)\n",
    "        accuracy = accuracy_score(y_true=y_test, y_pred=best_preds)\n",
    "        \n",
    "        if recall >= min_recall and precision >= min_precision and recall > threshold_recall:\n",
    "            threshold = current_threshold\n",
    "            threshold_recall = recall\n",
    "            threshold_precision = precision\n",
    "            threshold_accuracy = accuracy\n",
    "        \n",
    "        if f1score > best_f1score:\n",
    "            best_f1score = f1score\n",
    "            \n",
    "    return threshold, threshold_precision, threshold_recall, best_f1score, threshold_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f6c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipeline.predict_proba(X_train)[:,1]\n",
    "y_pred_test = pipeline.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "599ff32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best threshold\n",
    "\n",
    "threshold_train, precision_train, recall_train, f1_train, accuracy_train = find_best_threshold(y_pred_train, y_train)\n",
    "threshold_test, precision_test, recall_test, f1_test, accuracy_test = find_best_threshold(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b73f68f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37,\n",
       " 0.6544683699654134,\n",
       " 0.8082116285478094,\n",
       " 0.7233630141135138,\n",
       " 0.6907337237340682)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(threshold_train, precision_train, recall_train, f1_train, accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35185a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38,\n",
       " 0.6501364877161055,\n",
       " 0.7877618522601985,\n",
       " 0.7124939700916546,\n",
       " 0.6820060622761092)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(threshold_test, precision_test, recall_test, f1_test, accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb1e8d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18408292, 0.39411487, 0.28027099, ..., 0.72012616, 0.49264036,\n",
       "       0.91259987])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cebb06c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_evolution():\n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    thresholds = []\n",
    "    lim = []\n",
    "\n",
    "\n",
    "    for i in range(100):\n",
    "        current_threshold = i / 100\n",
    "\n",
    "        thresholds.append(current_threshold)\n",
    "        best_preds = y_pred_test > current_threshold\n",
    "\n",
    "        precision.append(precision_score(y_true=y_test, y_pred=best_preds, pos_label=True))\n",
    "        recall.append(recall_score(y_true=y_test, y_pred=best_preds, pos_label=True))\n",
    "        accuracy.append(accuracy_score(y_true=y_test, y_pred=best_preds))\n",
    "        \n",
    "        lim.append(0.5)\n",
    "    \n",
    "\n",
    "    plt.plot(thresholds, precision, label='precision')\n",
    "    plt.plot(thresholds, recall, label='recall')\n",
    "    plt.plot(thresholds, accuracy, label='accuracy')\n",
    "    #plt.plot(thresholds, lim, label='lim')\n",
    "\n",
    "    plt.xlabel('Threshold');\n",
    "    plt.legend()\n",
    "\n",
    "    plt.gcf().set_size_inches(12,4)\n",
    "    plt.gcf().savefig(\"images/precision_recall_evolution.pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score(y_pred_test > 0.62, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba328bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Balançar os dados para que fique 50-50 entre readmitted e não readmitted (eliminar os corrompidos, mais o que foir preciso)\n",
    "# 2. Código para descobrir o melhor threshold\n",
    "# 3. Verificar descriminação, adaptar função abaixo\n",
    "# 4. Testar vários modelos diferentes, escolher o melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f711c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_categories = variables_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocess_pieline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f99a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_transformed['age'] = X_test['age']\n",
    "#                             .apply(lambda value: known_categories['age']['mapping'](value))\n",
    "#                             .astype(known_categories['age']['type']))\n",
    "X_test_transformed['gender'] = (X_test['gender']\n",
    "                                .apply(lambda value: known_categories['gender']['mapping'](value))\n",
    "                                .astype(known_categories['gender']['type']))\n",
    "X_test_transformed['race'] = (X_test['race']\n",
    "                              .apply(lambda value: known_categories['race']['mapping'](value))\n",
    "                              .astype(known_categories['race']['type']))\n",
    "X_test_transformed['medical_specialty'] = (X_test['medical_specialty']\n",
    "                                           .apply(lambda value: known_categories['medical_specialty']['mapping'](value))\n",
    "                                           .astype(known_categories['medical_specialty']['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4930280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_no_discrimination(X_test, y_true, y_pred, sensitive_column='SubjectRaceCode', max_diff=0.05):\n",
    "    \"\"\"\n",
    "    Verifies that no subdeparment has discrimination in between protected races\n",
    "    \"\"\"\n",
    "    \n",
    "    departments = X_test['medical_specialty'].unique()\n",
    "    sensitive_classes = X_test[sensitive_column].unique()\n",
    "    \n",
    "    is_satisfied = True\n",
    "    problematic_departments = []\n",
    "    good_deparments = []\n",
    "    counter = {}\n",
    "    for department in departments:\n",
    "        precisions = {}\n",
    "        counter[department] ={}\n",
    "        for sensitive_class in sensitive_classes:\n",
    "            mask = (X_test[sensitive_column] == sensitive_class) & (X_test['medical_specialty'] == department)\n",
    "            if mask.sum() and mask.sum() > 20:\n",
    "                precisions[sensitive_class] = precision_score(y_true[mask], y_pred[mask], pos_label=1)\n",
    "                counter[department][sensitive_class] = mask.sum()\n",
    "        \n",
    "        if precisions:\n",
    "            diff = np.max(list(precisions.values())) - np.min(list(precisions.values()))\n",
    "            if diff > max_diff:\n",
    "                is_satisfied = False\n",
    "                problematic_departments.append((department, diff, precisions))\n",
    "            else:\n",
    "                good_deparments.append((department, diff, precisions))\n",
    "\n",
    "    return is_satisfied, problematic_departments, good_deparments, counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_no_discrimination(X_test, y_true, y_pred, sensitive_column='SubjectRaceCode', max_diff=0.05, min_samples=50):\n",
    "    \"\"\"\n",
    "    Verifies that no subdeparment has discrimination in between protected races\n",
    "    \"\"\"\n",
    "    \n",
    "    departments = X_test['medical_specialty'].unique()\n",
    "    sensitive_classes = X_test[sensitive_column].unique()\n",
    "    \n",
    "    is_satisfied = True\n",
    "    problematic_departments = []\n",
    "    good_deparments = []\n",
    "    ignored_departments = []\n",
    "    for department in departments:\n",
    "        precisions = {}\n",
    "        for sensitive_class in sensitive_classes:\n",
    "            mask = (X_test[sensitive_column] == sensitive_class) & (X_test['medical_specialty'] == department)\n",
    "            if np.sum(mask) > min_samples:\n",
    "                precisions[sensitive_class] = precision_score(y_true[mask], y_pred[mask], pos_label=1)\n",
    "                \n",
    "        if len(precisions) > 1:    \n",
    "            diff = np.max(list(precisions.values())) - np.min(list(precisions.values()))\n",
    "\n",
    "            if diff > max_diff:\n",
    "                is_satisfied = False\n",
    "                problematic_departments.append((department, diff, precisions))\n",
    "            else:\n",
    "                good_deparments.append((department, diff, precisions))\n",
    "        else:\n",
    "            ignored_departments.append((department, None, []))\n",
    "    \n",
    "    global_precisions = {}\n",
    "    for sensitive_class in sensitive_classes:\n",
    "        mask = (X_test[sensitive_column] == sensitive_class)\n",
    "        if np.sum(mask) > min_samples:\n",
    "            global_precisions[sensitive_class] = precision_score(y_true[mask], y_pred[mask], pos_label=1)\n",
    "    \n",
    "    if len(precisions) > 1:    \n",
    "        diff = np.max(list(precisions.values())) - np.min(list(precisions.values()))\n",
    "        if diff > max_diff:\n",
    "            is_satisfied = False\n",
    "        \n",
    "    return is_satisfied, problematic_departments, good_deparments, global_precisions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_satisfied, problematic_departments, good_deparments, global_precisions = verify_no_discrimination(X_test_transformed, y_test, y_pred_test > 0.61, sensitive_column='gender', max_diff=0.05, min_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_deparments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar modelo sem sensitve classes\n",
    "# Gráfico com feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
