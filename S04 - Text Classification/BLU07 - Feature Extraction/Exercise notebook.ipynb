{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12bea12324c032d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rafael.gil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import hashlib # for grading\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from numpy.testing import assert_allclose, assert_almost_equal\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SKLearn related imports\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f07b8631beb0508c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q1. S&P 500 Companies\n",
    "\n",
    "For the first question, you will be making use of regex. In particular, you have a list of companies currently in the S&P 500, their [stock tickers](https://en.wikipedia.org/wiki/Ticker_symbol) (an abbreviation used to uniquely identify publicly traded shares of a particular stock on a particular stock market), and their industries, and you'll have to answer some very specific questions about that list.\n",
    "\n",
    "Start by loading the data into a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c533ada39c512c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "path = \"data/SP500.txt\"\n",
    "companies = []\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    companies = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ecb61cd23d78a49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3M Company (MMM) -- Industrials',\n",
       " 'Abbott Laboratories (ABT) -- Health Care',\n",
       " 'AbbVie Inc. (ABBV) -- Health Care',\n",
       " 'ABIOMED Inc (ABMD) -- Health Care',\n",
       " 'Accenture plc (ACN) -- Information Technology']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the format\n",
    "companies[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25dda75958bdaef9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the first item, for example, `3M Company` is the company name, `MMM` is the ticker symbol, and `Industrials` is the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df341d1f1838c29e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q1.a)\n",
    "\n",
    "First, we want to know which companies belong to the Real Estate or Health Care sectors. Return the full strings that include these companies in a list assigned to a variable `ans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7cddd8e2e48afb31",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans = [ x for x in companies if re.search(\"(Real Estate)|(Health Care)\", x) != None ]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5a358ed83c473214",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans) == 93\n",
    "assert hashlib.sha256(' '.join(ans).encode()).hexdigest() == \\\n",
    "    'b25ef38e29cc7d975a651e93fc201b9a83cfdb35a0a79d6068d1e29325d3fa8f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e3cc736b933d71e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q1.b)\n",
    "\n",
    "Next, find the companies that start with an initial consisting of a capital letter followed by a period (e.g. `A.`). Return a list of the companies (the full strings) in the variable `ans_initials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bf14a2df3dd3e4e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans_initials = [ x for x in companies if re.search(r\"^[A-Z]\\.\", x) != None ]\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-19b61469674be299",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies starting with an initial:  7\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of companies starting with an initial: \" , len(ans_initials))\n",
    "assert 'A.O. Smith Corp (AOS) -- Industrials' in ans_initials\n",
    "assert 'D. R. Horton (DHI) -- Consumer Discretionary' in ans_initials\n",
    "assert 'Arthur J. Gallagher & Co. (AJG) -- Financials' not in ans_initials\n",
    "assert 'Berkshire Hathaway (BRK.B) -- Financials' not in ans_initials\n",
    "assert hashlib.sha256(' '.join(ans_initials).encode()).hexdigest() == \\\n",
    "    '999cbcf37711021cecdda234015f87d8785f0d25f1200d43be4cf0ac7239aaa7'\n",
    "assert len(ans_initials) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6727f8213243afc0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q1.c)\n",
    "\n",
    "Now, extract only the company names whose stock tickers contain just a single letter. For example, if the string looks like `Lisbon Data Science Academy (L) -- Education`, return just `Lisbon Data Science Academy`. Store the company names as a list called `ans_single`.\n",
    "\n",
    "For an extra challenge, try to do this using just one regex pattern. You may want to use `re.search()` and read about [capturing groups](https://docs.python.org/3/howto/regex.html#grouping), and don't forget you can use tools like https://regex101.com/ to test your regexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-447eb675481e47fd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agilent Technologies Inc',\n",
       " 'AT&T Inc.',\n",
       " 'Citigroup Inc.',\n",
       " 'Dominion Energy',\n",
       " 'Ford Motor Company',\n",
       " 'Jacobs Engineering Group',\n",
       " 'Kellogg Co.',\n",
       " 'Loews Corp.',\n",
       " 'Realty Income Corporation',\n",
       " 'Visa Inc.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = map(lambda x: re.search(r\"^(.*) \\(.\\)\", x), companies)\n",
    "\n",
    "ans_single = [ x.group(1) for x in match if x != None ]\n",
    "ans_single\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-535072609d84d577",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans_single) == 10\n",
    "assert hashlib.sha256(' '.join(ans_single).encode()).hexdigest() == 'b449c503fabbec88da870a63b6bda074496741113d7c04f204ad597a31ca23fb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0409818769bbf3d0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q2. Sports News (preprocessing)\n",
    "\n",
    "Here is a subset of data taken from the 20 Newsgroups dataset, a classic text classification dataset, which we can download directly from [scikit-learn](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset). To keep things simple, we will only be focusing on two of the categories, `rec.sport.baseball` and `rec.sport.hockey`. Our goal will be to classify whether news articles are about the sport of baseball or hockey.\n",
    "\n",
    "First, let's prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5684ea0f3e42ccee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is how the data was originally downloaded\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# categories = [\n",
    "#  'rec.sport.baseball',\n",
    "#  'rec.sport.hockey',\n",
    "# ]\n",
    "\n",
    "# # returns a list of strings X representing the articles to classify, and the category labels y as a numpy array\n",
    "# X, y = fetch_20newsgroups(subset=\"all\", remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "#                           categories=categories, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load the data from pickle files instead\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"data/20_newsgroups_baseball_hockey_X.pkl\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(\"data/20_newsgroups_baseball_hockey_y.pkl\", \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbdc0548dd699460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check the data size and distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1993\n",
      "Distribution of classes: {0: 994, 1: 999}\n"
     ]
    }
   ],
   "source": [
    "def get_data_stats(X, y):\n",
    "    print(f\"Size of dataset: {len(X)}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Distribution of classes: {dict(zip(unique, counts))}\")\n",
    "\n",
    "get_data_stats(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-808b90ccd21d360d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since the classes are evenly distributed, we can use a regular train/dev/test split. We'll use a dev and test size of 10% of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a524119b37972d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1594\n",
      "Dev size: 199\n",
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "# train dev test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(f\"Train size: {len(X_train)}\\nDev size: {len(X_dev)}\\nTest size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e93f9088c1da685e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since the goal is to turn the strings on X into useful features, now we will be performing common preprocessing operations on the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-addc0c904c359402",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.a)\n",
    "\n",
    "First tokenize the data. Implement the function to receive a list of strings and an NLTK-style tokenizer, and return the list but with tokenized strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b7930a61806e32",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_tokenizer(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings that is the tokenization of the given data by applying the given tokenizer.\n",
    "    E.g. for an input [\"This is a test!\", \"No, it can't be\"],\n",
    "      it returns [\"This is a test !\", \"No , it can ' t be\"]\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings containing the text to tokenize\n",
    "    tokenizer - nltk tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return [ \" \".join(tokenizer.tokenize(text)) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f829c5a222c54690",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "data_tok = apply_tokenizer(X_train, tokenizer)\n",
    "\n",
    "assert len(data_tok) == 1594\n",
    "assert len([w for s in data_tok for w in s.split(\" \")]) == 333566\n",
    "assert hashlib.sha256(data_tok[1234].encode()).hexdigest() == \\\n",
    "    'bd70c45292aafb1430f3dae58dd7b3732ff2ddebc8acb64976a38efbe7945215'\n",
    "assert hashlib.sha256(data_tok[567].encode()).hexdigest() == \\\n",
    "    '0de358e31d950ef321b2f3d762b525a8ab1e65e0a2c392633e6984e40253f2e4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b76d100b971a777f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.b)\n",
    "\n",
    "The second step you will implement is lowercasing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee47fb5a45fbd622",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_lowercase(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with all the tokens lowercased.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to be lowercased\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return [ text.lower() for text in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7979e12840663ea2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc = apply_lowercase(data_tok)\n",
    "\n",
    "assert len(data_tok_lc) == 1594\n",
    "assert len([w for s in data_tok_lc for w in s.split(\" \")]) == 333566\n",
    "assert hashlib.sha256(data_tok_lc[1234].encode()).hexdigest() == \\\n",
    "    'e12bd8bec884721329792d49085e8e6b268c8129da7ed638b06ccdf3ea49c7a5'\n",
    "assert hashlib.sha256(data_tok_lc[567].encode()).hexdigest() == \\\n",
    "    '4476776aa3ea52c7580c592bfeb0e2286a79ec1bb615188518a167a73429b424'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8044c14c20583cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.c)\n",
    "\n",
    "Now implement a function that filters the stopwords. We will use NLTK's built-in English stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f0dea2c5108c93a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42ecb29c8fe117f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_stopwords(data, stopword_list):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, where the strings do not contain any of\n",
    "        the stopwords in the given list.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings to filter stopwords from\n",
    "    stopword_list - list of stopwords to filter out\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the stopwords from the text\n",
    "    # data_no_stopwords = ...\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return [ \" \".join( [ word for word in text.split() if word not in stopword_list ] ) for text in data ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f70da0255ea6e291",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc_nosw = apply_filter_stopwords(data_tok_lc, stopword_list)\n",
    "assert len(data_tok_lc_nosw) == 1594\n",
    "assert len([w for s in data_tok_lc_nosw for w in s.split(\" \")]) == 239401\n",
    "assert hashlib.sha256(data_tok_lc_nosw[1234].encode()).hexdigest() == \\\n",
    "    '9d48d50a7a0dcd3676c13419750a3aad75006e165d2c614e0fe7e8f98d521b84'\n",
    "assert hashlib.sha256(data_tok_lc_nosw[567].encode()).hexdigest() == \\\n",
    "    'd1d745ba13b4588eb2356dd3a5119113e391bfe226bc4126338391bf03830ecf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d0cb317596faa2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.d)\n",
    "\n",
    "After filtering stopwords, we want to remove punctuation from the text as well. Make use of `string.punctuation` to do so. Make sure to remove all punctuation and not only distinct tokens that only contain punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0cd3cf5cc97a8f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_puct(text):\n",
    "    for character in string.punctuation:\n",
    "            text = text.replace(character, '')\n",
    "    \n",
    "    return text\n",
    "    \n",
    "def apply_filter_punct(data):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with no punctuation.\n",
    "    \n",
    "    Args:\n",
    "    data - list of strings from which to remove punctuation\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return [ remove_puct(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31c9a6a65413aef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_tok_lc_nosw_nopunct = apply_filter_punct(data_tok_lc_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-925e418acc339a2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Normalize whitespaces\n",
    "\n",
    "Run the following function on `data_tok_lc_nosw_nopunct` before checking your answers, in case extra whitespaces cause the asserts to fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67539c50de422305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_whitespace(data):\n",
    "    return [re.sub(r\"^\\s+|\\s+$|(?<=\\s)\\s*\", \"\", text) for text in data]\n",
    "\n",
    "data_tok_lc_nosw_nopunct_norm = normalize_whitespace(data_tok_lc_nosw_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-650a677a3a01d1bf",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(data_tok_lc_nosw_nopunct_norm) == 1594\n",
    "assert len([w for s in data_tok_lc_nosw_nopunct_norm for w in s.split(\" \")]) == 174486\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm[1234].encode()).hexdigest() == \\\n",
    "    '57b0c8646701140d4edfb7112b812c0df7cdebfe7db1a58811c9229f906f6ca9'\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm[567].encode()).hexdigest() == \\\n",
    "    'a39ba5c27525d163573d484284aff0228118db129aeae1623020ac11b063a952'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38d66dd89731e114",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.e)\n",
    "\n",
    "The last preprocessing step you are going to implement is stemming. Implement the function to receive an NLTK-style stemmer and return the text as a string with the stemmer applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a831ba989f3e50e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_stemmer(data, stemmer):\n",
    "    \"\"\"\n",
    "    Returns a list of strings, with stemmed data.\n",
    "    \n",
    "    Args:\n",
    "    data - list with text to stem\n",
    "    stemmer - instance of stemmer to use\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return [ \" \".join(map(stemmer.stem, text.split())) for text in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3596a6510ebbda3d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "data_tok_lc_nosw_nopunct_norm_stem = apply_stemmer(data_tok_lc_nosw_nopunct_norm, stemmer)\n",
    "\n",
    "assert len(data_tok_lc_nosw_nopunct_norm_stem) == 1594\n",
    "assert len([w for s in data_tok_lc_nosw_nopunct_norm_stem for w in s.split(\" \")]) == 174486\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm_stem[1234].encode()).hexdigest() == \\\n",
    "    'f8e83239a3658073219232f17c270a0df20d4cebfb517ce935d395e02467009f'\n",
    "assert hashlib.sha256(data_tok_lc_nosw_nopunct_norm_stem[567].encode()).hexdigest() == \\\n",
    "    '4f36be21767ee2ad747baecf0d67b8b082c8c65f334fce896036870a75570fb0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bfe5aed6ebdbb26",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q2.f)\n",
    "\n",
    "Finally, join everything in a function, that applies the steps in the following order:\n",
    "* Tokenization\n",
    "* Lowercasing\n",
    "* Filtering stopwords\n",
    "* Filtering punctuation\n",
    "* Normalizing whitespace\n",
    "* Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea5b2305431c20dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, lower=True, remove_punct=True, stopwords=[], stemmer=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        self.stopwords = stopwords\n",
    "    \n",
    "    def clean_sentences(self, data):\n",
    "                \n",
    "        # Split sentence into list of words\n",
    "        sentences_preprocessed = apply_tokenizer(data, tokenizer) # data.split()\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Lowercase\n",
    "        if self.lower:\n",
    "            sentences_preprocessed = apply_lowercase(sentences_preprocessed)\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "        if self.stopwords:\n",
    "            sentences_preprocessed = apply_filter_stopwords(sentences_preprocessed, self.stopwords)\n",
    "            # YOUR CODE HERE\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            sentences_preprocessed = apply_filter_punct(sentences_preprocessed)\n",
    "            # YOUR CODE HERE\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        sentences_preprocessed = normalize_whitespace(sentences_preprocessed)\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            sentences_preprocessed = apply_stemmer(sentences_preprocessed, self.stemmer)\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "        return sentences_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a4c1aa16cea2ffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text_cleaner = TextCleanerTransformer(\n",
    "    WordPunctTokenizer(),\n",
    "    lower=True, \n",
    "    remove_punct=True, \n",
    "    stopwords=stopwords.words('english'),\n",
    "    stemmer=SnowballStemmer(\"english\"),\n",
    ")\n",
    "\n",
    "X_train_pre = text_cleaner.clean_sentences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4a87d0c9b1f20f7e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(X_train_pre) == 1594\n",
    "assert len([w for s in X_train_pre for w in s.split(\" \")]) == 174486\n",
    "assert X_train_pre[1234] == (\"mcgwire carter see justif bond thoma tend higher bat averag major differ \"\n",
    "    \"see mcgwire carter carter draw walk pitcher afraid throw strike carter\")\n",
    "assert X_train_pre[567] == (\"best one saw last year willi mcgee matthew think philli fierc line \"\n",
    "    \"drive still rise hit second deck facad vet willi mcgee one homerun last year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f48abbdab8acc3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q3. Text classification\n",
    "\n",
    "We will now use what we've learned to try to classify the topic of these articles as baseball or hockey. Let's first load the preprocessed data (slightly different from the answer to Q2) and double-check the balance of the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cfef332c9bd3d0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    \"\"\"\n",
    "    Loads a tsv file with the label in the first column and the text in the second column.\n",
    "    Returns two lists, one containing only the text and one containing the labels\n",
    "    \n",
    "    Args:\n",
    "    file_name: path to input file\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    texts = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(\"\\t\")\n",
    "            labels.append(int(label))\n",
    "            texts.append(text)\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99de6cc5a4a3ff52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre, y_train = load_dataset('data/sports_train_preprocessed.tsv')\n",
    "X_dev_pre, y_dev = load_dataset('data/sports_dev_preprocessed.tsv')\n",
    "X_test_pre, y_test = load_dataset('data/sports_test_preprocessed.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfca3c5348fd2262",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1535\n",
      "Distribution of classes: {0: 758, 1: 777}\n"
     ]
    }
   ],
   "source": [
    "get_data_stats(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aaf6fbf5dbc51f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 196\n",
      "Distribution of classes: {0: 92, 1: 104}\n"
     ]
    }
   ],
   "source": [
    "get_data_stats(X_dev_pre, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e5147de37fa0351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So, we should be aiming for much better than 53% accuracy, which is what we would get if we naively predicted `1` (hockey) for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a844631e7326ff6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.a)\n",
    "\n",
    "First, we'll look at the top X ngrams in each category to see if anything is interesting. Write a function that returns the top n ngrams of the data, limited to a given label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36567f8f392a4836",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def top_ngrams_for_category(text, labels, filter_label, top_n=10, ngram_size=1):\n",
    "    \"\"\"\n",
    "    Filters the data to the desired label, constructs a counter of ngrams\n",
    "    Returns the top n ngrams\n",
    "    \n",
    "    Args:\n",
    "    text: list of text strings to get ngrams from\n",
    "    labels: categories corresponding to text\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    top_n: top n ngrams to return\n",
    "    ngram_size: the \"n\" in ngram (e.g. if ngram_size=2, return only bigrams)\n",
    "    \"\"\"\n",
    "    # First, filter text to desired category\n",
    "    text_filtered = [ text[i] for i in range(len(text)) if labels[i] == filter_label ]\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #print(text_filtered)\n",
    "    \n",
    "    # Create list of ngrams\n",
    "    ngram_list = [ ngram for t in text_filtered for ngram in list(nltk.ngrams(t.split(), ngram_size)) ]\n",
    "    # hint: make the ngrams in the list an immutable data type so they can be used as dict keys later,\n",
    "    # tuples for example\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Count occurances of each ngram\n",
    "    # hint: use collections.Counter\n",
    "    ngram_counter = Counter(ngram_list).most_common(top_n)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # return top_n most common ngrams\n",
    "    return ngram_counter #[ ngram[0] for ngram in ngram_counter ]\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cca0190cfba4ad83",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_10_unigrams_baseball = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_baseball == [(('0',), 1899),\n",
    "                                     (('1',), 718),\n",
    "                                     (('game',), 561),\n",
    "                                     (('year',), 505),\n",
    "                                     (('2',), 481),\n",
    "                                     (('3',), 453),\n",
    "                                     (('5',), 408),\n",
    "                                     (('would',), 383),\n",
    "                                     (('4',), 342),\n",
    "                                     (('one',), 311)]\n",
    "top_7_bigrams_baseball = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=7, ngram_size=2)\n",
    "assert top_7_bigrams_baseball == [(('0', '0'), 240),\n",
    "                                 (('last', 'year'), 118),\n",
    "                                 (('1', '0'), 94),\n",
    "                                 (('0', '1'), 72),\n",
    "                                 (('new', 'york'), 66),\n",
    "                                 (('00', '00'), 66),\n",
    "                                 (('1', '2'), 61)]\n",
    "top_10_unigrams_hockey = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_hockey == [(('0',), 5104),\n",
    "                                     (('1',), 3657),\n",
    "                                     (('2',), 2571),\n",
    "                                     (('3',), 1804),\n",
    "                                     (('4',), 1569),\n",
    "                                     (('6',), 1159),\n",
    "                                     (('5',), 1135),\n",
    "                                     (('7',), 989),\n",
    "                                     (('game',), 972),\n",
    "                                     (('team',), 743)]\n",
    "top_5_trigrams_hockey = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=5, ngram_size=3)\n",
    "assert top_5_trigrams_hockey == [(('0', '0', '0'), 691),\n",
    "                                 (('0', '1', '1'), 422),\n",
    "                                 (('1', '0', '1'), 303),\n",
    "                                 (('1', '0', '0'), 184),\n",
    "                                 (('1', '1', '0'), 171)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05f81b8870270b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Looking at the top ngrams for each category, it doesn't seem like a BoW model will be very interesting, but let's try anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a096ee6776427b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.b)\n",
    "To begin, let's streamline our pipeline in a nice function. We'll use sklearn's `CountVectorizer` instead of the function we wrote. We'll also use the `MultinomialNB` classifier to make predictions on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af90809e6c74e780",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate(X_train, X_dev, y_train, y_dev, ngram_range=(1,1), max_features=None):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's Pipeline and return it along with the predictions and the\n",
    "    current accuracy in the validation set. Print the classification report as well.\n",
    "    Assume the documents are already preprocessed\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed articles in training data\n",
    "    X_dev - preprocessed articles in dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the pipeline containing the countvectorizer and the multinomial NB classifier\n",
    "    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=ngram_range, max_features=max_features)),\n",
    "                   ('clf', MultinomialNB())])\n",
    "    \n",
    "    # Train the classifier\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_dev_pred = text_clf.predict(X_dev)\n",
    "    # print the classification report\n",
    "    acc = np.mean(y_dev_pred == y_dev)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "    return text_clf, y_dev_pred, acc\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-97ba1cceed5a53f9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        92\n",
      "           1       0.97      0.86      0.91       104\n",
      "\n",
      "    accuracy                           0.91       196\n",
      "   macro avg       0.91      0.91      0.91       196\n",
      "weighted avg       0.91      0.91      0.91       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "\n",
    "# check same as before\n",
    "assert_allclose(clf['clf'].intercept_, np.array([-0.68084531]), rtol=1e-3)\n",
    "assert ' '.join(str(i) for i in y_dev_pred[:20]) == \"0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0\"\n",
    "assert hashlib.sha256(' '.join(str(i) for i in y_dev_pred).encode()).hexdigest() == \\\n",
    "    \"5e67c5da0e5fc28a5d834ee9f12b93bc7c20bd26347fc9f02a36d50bc000b573\"\n",
    "assert_allclose(acc, 0.91, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7678b7610a7200f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: fact ferreira origin strategi troika proceed simpli continu implement exact radic shift polici oust someth peopl seem forget real question whether well ferreira could stay whether basic strategi flaw sinc ferreira quoat say go someth differ anaheim duck guess good practic paper tweak bit second time around one also wonder whether strategi would lot better injuri whether complain weather earthquak collaps root cellar let also forget ferreira came close trade kelli kisio rumor heard true strong object aspect shark manag probabl lot ouster three head consensus orient gm imagin second shark would today fax machin jam especi unhappi player play well accus mullen tank motiv simpli kind thing affect team exact time let skriko go yet major injuri bug kill us later much rather skriko around someon like dean kolstad point choic sinc choic one skriko vs someon like john carter think right choic made time period\n",
      "Predicted: 0, Actual: 1\n",
      "\n",
      "Sentence: welcom aboard sinc seen yet year preced year let say\n",
      "Predicted: 0, Actual: 1\n",
      "\n",
      "Sentence: think owner hockey well miami sinc lot peopl northeast spend winter florida everi year coverag someon come money sinc broadcast right expens 0 02 dale\n",
      "Predicted: 0, Actual: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we should also look at some misclassified examples\n",
    "for text, pred, true in zip(X_dev_pre[:50], y_dev_pred[:50], y_dev[:50]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c7cbbc0c3275557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So just with the simplest BoW model we already get an F-score of 0.91! But let's see if we can do even better... In the misclassified examples, the last one even contains the word \"hockey\" but was misclassified. And slightly tricker, but the first example contains the team name \"Anaheim Ducks,\" which is an NHL team. We should be able to get those right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4fd66e62c165a4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3.c)\n",
    "Run the pipeline for different ngram ranges and/or with different values for max_features, until you get an accuracy of at least 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e75ac8652cc7e741",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf,y_dev_pred, acc = train_and_validate(...)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "acc = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-722d1b4ff466bdd7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc >= 0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af52f1de74f79623",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: fact ferreira origin strategi troika proceed simpli continu implement exact radic shift polici oust someth peopl seem forget real question whether well ferreira could stay whether basic strategi flaw sinc ferreira quoat say go someth differ anaheim duck guess good practic paper tweak bit second time around one also wonder whether strategi would lot better injuri whether complain weather earthquak collaps root cellar let also forget ferreira came close trade kelli kisio rumor heard true strong object aspect shark manag probabl lot ouster three head consensus orient gm imagin second shark would today fax machin jam especi unhappi player play well accus mullen tank motiv simpli kind thing affect team exact time let skriko go yet major injuri bug kill us later much rather skriko around someon like dean kolstad point choic sinc choic one skriko vs someon like john carter think right choic made time period\n",
      "Predicted: 0, Actual: 1\n",
      "\n",
      "Sentence: welcom aboard sinc seen yet year preced year let say\n",
      "Predicted: 0, Actual: 1\n",
      "\n",
      "Sentence: think owner hockey well miami sinc lot peopl northeast spend winter florida everi year coverag someon come money sinc broadcast right expens 0 02 dale\n",
      "Predicted: 0, Actual: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at some misclassified examples again\n",
    "for text, pred, true in zip(X_dev_pre[:50], y_dev_pred[:50], y_dev[:50]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711b6cc0145d445c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Depending on your chosen hyperparameters, the 2 examples we missed earlier that we should have gotten should be correct now! But let's see if we can get even better performance now by using the relative importance of ngrams with TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28921443e50007c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4. TF-IDF\n",
    "\n",
    "Similarly to how we found the top ngrams before we started working with BoW, we will now find the most important unigrams, inverse weighted by document frequency.\n",
    "\n",
    "#### Q4.a)\n",
    "\n",
    "First, implement TF-IDF on a dataframe representing a Bag of Words model of the data. Here is a reminder of the TF-IDF formula:\n",
    "\n",
    "$$ tfidf _{t, d} =(log_2{(1 + tf_{t,d})})*(log_2{(1 + \\frac{N}{df_{t}})})  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start you off with the BoW representation, in pandas dataframe format\n",
    "vec = CountVectorizer()\n",
    "BoW_train = vec.fit_transform(X_train_pre)\n",
    "BoW_train_df = pd.DataFrame(BoW_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b915bab713aba13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(BoW_df):\n",
    "    \"\"\"\n",
    "    Returns pandas dataframe of a tfidf representation from a BoW representation dataframe.\n",
    "\n",
    "    Args:\n",
    "    BoW_df - dataframe with document word counts (Bag of Words)\n",
    "    \"\"\"\n",
    "    # remember that the BoW representation is raw counts, it is not normalized by the length of each text\n",
    "    # first transform the df into term frequencies, where the counts are normalized\n",
    "    # also double check the formula above for additional transformations applied to the tf expression\n",
    "    # use np.log2(x) for base-2 log\n",
    "    tf = BoW_df.div(BoW_df.sum(axis=1), axis=0)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "    # now we need a function that computes the idf side of the expression\n",
    "    # it operates over a column (a word in the vocab), where the column contains each doc's count of that word\n",
    "    # def _idf(column):\n",
    "    #   return (...)\n",
    "    # YOUR CODE HERE\n",
    "    _idf = lambda column: np.log2(1 + len(column) / sum(column > 0))\n",
    "\n",
    "    # now weight the term frequencies by the idfs\n",
    "    tf_idf = (np.log2(1 + tf)).multiply(BoW_df.apply(_idf))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-86090d8867691e1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df = tfidf(BoW_train_df)\n",
    "assert math.isclose(tfidf_df[12609][2], 0.1223836, abs_tol=0.0001)\n",
    "assert math.isclose(tfidf_df[0][1531], 0.03629635, abs_tol=0.0001)\n",
    "assert math.isclose(tfidf_df[8][6], 0.019335965, abs_tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.b)\n",
    "\n",
    "Now that we have our TF-IDF representation, we can proceed with getting the most important words per category. \n",
    "\n",
    "Let's write a small helper function first to get the vocabulary in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vocab from CountVectorizer, which is of the format {\"word\": idx, ...}\n",
    "vocab_word_2_idx = vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4cf0289cdb72e49a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# write a function to convert this vocab to the format {idx: \"word\", ...}\n",
    "\n",
    "def reverse_vocab(vocab_word_to_index):\n",
    "    \"\"\"\n",
    "    Converts a vocabulary dictionary with words as keys and indices as values to a \n",
    "        new dictionary with indices as keys and words as values\n",
    "    \n",
    "    Args:\n",
    "    vocab_word_to_index: vocabulary dict of the format {\"word\": 0, \"hello\": 1, ...}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return {v: k for k, v in vocab_word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c86ba6062add631",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab_idx_2_word = reverse_vocab(vocab_word_2_idx)\n",
    "assert len(vocab_idx_2_word) == 12613\n",
    "assert vocab_idx_2_word[11714] == \"two\"\n",
    "assert vocab_idx_2_word[2847] == \"boston\"\n",
    "assert vocab_idx_2_word[8762] == \"palmer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.c)\n",
    "\n",
    "Finally, write a function to return the N most important words in a single category according to TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12603</th>\n",
       "      <th>12604</th>\n",
       "      <th>12605</th>\n",
       "      <th>12606</th>\n",
       "      <th>12607</th>\n",
       "      <th>12608</th>\n",
       "      <th>12609</th>\n",
       "      <th>12610</th>\n",
       "      <th>12611</th>\n",
       "      <th>12612</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>0.036296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1535 rows × 12613 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9      \\\n",
       "0     0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1530  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1531  0.036296    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1532  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1533  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1534  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  12603  12604  12605  12606  12607  12608     12609  12610  12611  \\\n",
       "0     ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "1     ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "2     ...    0.0    0.0    0.0    0.0    0.0    0.0  0.122384    0.0    0.0   \n",
       "3     ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "4     ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...       ...    ...    ...   \n",
       "1530  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "1531  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "1532  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "1533  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "1534  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "\n",
       "      12612  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "1530    0.0  \n",
       "1531    0.0  \n",
       "1532    0.0  \n",
       "1533    0.0  \n",
       "1534    0.0  \n",
       "\n",
       "[1535 rows x 12613 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00f14b79ff68d32e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_tfidf_words_for_category(tfidf_df, labels, filter_label, vocabulary, top_n=10):\n",
    "    \"\"\"\n",
    "    Returns the top n most important words for the given label, with the given vocabulary\n",
    "    and corresponding tfidf representation of some text data\n",
    "    \n",
    "    Args:\n",
    "    tfidf_df: a dataframe of the tfidf representation of some text (columns=words, rows=documents)\n",
    "    labels: categories corresponding to documents in tfidf_df\n",
    "    filter_label: the label to filter the data on before getting top n words\n",
    "    vocabulary: a dict of the format {idx: \"word\", ...}\n",
    "    top_n: top n words to return\n",
    "    \"\"\"\n",
    "    # First, filter tfidf to desired category    \n",
    "    tfidf_filt = tfidf_df[ pd.Series(map(lambda x: x == filter_label, labels)) ]\n",
    "\n",
    "    # YOUR CODE HERE    \n",
    "    \n",
    "    # Get the top n words of the current label, according to tfidf\n",
    "    # There are several ways to do this, but here are some hints\n",
    "    # 1) Sum the filtered df to get the total value per word\n",
    "    # 2) Sort\n",
    "    # 3) Replace indices with words and return the top_n\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    indexes = tfidf_filt.sum(axis=0).nlargest(top_n).sort_values(ascending=False).index.values\n",
    "    \n",
    "    return list(map(lambda x: vocabulary[x], indexes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b51198b450763c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_15_hockey = top_tfidf_words_for_category(tfidf_df, y_train, 1, vocab_idx_2_word, top_n=15)\n",
    "assert top_15_hockey == ['game',\n",
    "     'team',\n",
    "     'hockey',\n",
    "     'play',\n",
    "     'would',\n",
    "     'player',\n",
    "     'playoff',\n",
    "     'go',\n",
    "     'one',\n",
    "     'year',\n",
    "     'nhl',\n",
    "     'get',\n",
    "     'espn',\n",
    "     'like',\n",
    "     'goal']\n",
    "top_20_baseball = top_tfidf_words_for_category(tfidf_df, y_train, 0, vocab_idx_2_word, top_n=20)\n",
    "assert top_20_baseball == ['game',\n",
    "     'year',\n",
    "     'basebal',\n",
    "     'pitch',\n",
    "     'hit',\n",
    "     'run',\n",
    "     'would',\n",
    "     'think',\n",
    "     'pitcher',\n",
    "     'one',\n",
    "     'know',\n",
    "     'cub',\n",
    "     'day',\n",
    "     'like',\n",
    "     'first',\n",
    "     'time',\n",
    "     'anyon',\n",
    "     'go',\n",
    "     'team',\n",
    "     'get']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a8bfb9ad7d5ec44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, these top words per category make a lot more sense than the ones from just BoW. Maybe this will help us make better predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2672054e4024a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4.d)\n",
    "\n",
    "Now, we will put everything together. Rewrite the train_and_validate function from Q3.b but using sklearn's `TfIdfTransformer`. Also, add kwargs for CountVectorizer's `max_df` and `min_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02453bb681cd33b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate_with_tfidf(X_train, X_dev, y_train, y_dev, ngram_range=(1,1),\n",
    "                                  max_features=None, max_df=1.0, min_df=1):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's Pipeline and return it along with the predictions and the\n",
    "    current accuracy in the validation set. Print the classification report as well.\n",
    "    Assume the documents are already preprocessed\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed articles in training data\n",
    "    X_dev - preprocessed articles in dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    max_df = max_df for CountVectorizer (int or float)\n",
    "    min_df = min_df for CountVectorizer (int or float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the pipeline containing the countvectorizer and the multinomial NB classifier\n",
    "    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=ngram_range, max_features=max_features, max_df=max_df, min_df=min_df)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB())])\n",
    "    \n",
    "    # Train the classifier\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_dev_pred = text_clf.predict(X_dev)\n",
    "    # print the classification report\n",
    "    acc = np.mean(y_dev_pred == y_dev)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "    return text_clf, y_dev_pred, acc\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ee1c189fe642928a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        92\n",
      "           1       0.92      0.96      0.94       104\n",
      "\n",
      "    accuracy                           0.93       196\n",
      "   macro avg       0.94      0.93      0.93       196\n",
      "weighted avg       0.93      0.93      0.93       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate_with_tfidf(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "\n",
    "assert hashlib.sha256(\" \".join([str(x) for x in list(y_dev_pred)]).encode()).hexdigest() == \\\n",
    "    \"1beda6d3a1226853b58518db5f7fcba362722f1f97b53f0af5c71c53fc28f686\"\n",
    "assert_allclose(acc, 0.93367, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: think lamont tryin sax left mess mind tri stir loos mental block sax suppos play left last night 4 14 rain like need add outfield team mental\n",
      "Predicted: 1, Actual: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As before, we should also look at some misclassified examples\n",
    "for text, pred, true in zip(X_dev_pre[:50], y_dev_pred[:50], y_dev[:50]):\n",
    "    if pred != true:\n",
    "        print(f\"Sentence: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26ada9070ceb8872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since \"outfield\" is clearly a baseball word, let's keep going and see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab54cc6297c36ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Q4.e)\n",
    "\n",
    "Use the `train_and_validate_with_tfidf` function you created before to train with different hyperparameters and get an accuracy score above 94% on the validation dataset. (This threshold is the same as what we got for plain CountVectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07b6f3694941ac8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf, _, acc = train_and_validate_with_tfidf(...)\n",
    "# YOUR CODE HERE\n",
    "acc = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-07b6f3694941ac81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc > 0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       103\n",
      "           1       0.94      0.96      0.95        92\n",
      "\n",
      "    accuracy                           0.95       195\n",
      "   macro avg       0.95      0.95      0.95       195\n",
      "weighted avg       0.95      0.95      0.95       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_vec = clf['tfidf'].transform(clf['vect'].transform(X_test_pre))\n",
    "y_test_pred = clf['clf'].predict(X_test_vec)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4aa5fa0188b8ce3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We ended up not being able to beat our baseline of BoW with TF-IDF, maybe because the dataset is small and very easy, and so a simple algorithm was enough. Still, in general, it's good to try TF-IDF for text classification tasks and have an understanding of how your results change with different hyperparameters!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
